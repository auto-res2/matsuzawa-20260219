# Run config for comparative method: Standard CoT
run_id: comparative-1-llama-3.1-8b-gsm8k

method:
  name: Standard-CoT
  type: comparative
  description: "Standard Chain-of-Thought with step-by-step reasoning"
  prompt_template: |
    Solve the problem. Think step by step, then output exactly: FINAL: <number>
    
    Problem: {q}
  single_call: false  # Standard CoT uses 3 separate calls (ORIGINAL, V1, V2)

model:
  name: Llama-3.1-8B-Instruct
  provider: openai  # OpenAI-compatible API (vLLM)
  base_url: null  # Will use OPENAI_BASE_URL env var
  api_key_env: OPENAI_API_KEY
  temperature: 0.0
  max_tokens: 800

dataset:
  name: GSM8K
  split: test
  n_samples: 200  # Full run uses 200
  cache_dir: .cache

inference:
  batch_size: 1
  perturbations:
    - type: sentence_shuffle
      seed_offset: 0
    - type: add_irrelevant
      text: " Note: the sky is blue."
