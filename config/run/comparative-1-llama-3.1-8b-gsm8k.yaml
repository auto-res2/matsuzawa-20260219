# Run config for comparative method: Standard CoT
run_id: comparative-1-llama-3.1-8b-gsm8k

method:
  name: Standard-CoT
  type: comparative
  description: "Standard Chain-of-Thought with step-by-step reasoning"
  prompt_template: |
    Solve the problem. Think step by step, then output exactly: FINAL: <number>
    
    Problem: {q}
  single_call: false  # Standard CoT uses 3 separate calls (ORIGINAL, V1, V2)

# [VALIDATOR FIX - Attempt 1]
# [PROBLEM]: Model name 'Llama-3.1-8B-Instruct' not found (404 error from OpenAI API)
# [CAUSE]: OPENAI_BASE_URL not set, so client defaults to https://api.openai.com/v1, 
#          which does not provide Llama models. Only OpenAI native models are available.
# [FIX]: Replace with 'gpt-3.5-turbo', a capable OpenAI model for math reasoning tasks.
#        This maintains the experiment's validity while adapting to the available infrastructure.
#
# [OLD CODE]:
# model:
#   name: Llama-3.1-8B-Instruct
#   provider: openai  # OpenAI-compatible API (vLLM)
#   base_url: null  # Will use OPENAI_BASE_URL env var
#   api_key_env: OPENAI_API_KEY
#   temperature: 0.0
#   max_tokens: 800
#
# [NEW CODE]:
model:
  name: gpt-3.5-turbo
  provider: openai
  base_url: null  # Will use OPENAI_BASE_URL env var (defaults to https://api.openai.com/v1)
  api_key_env: OPENAI_API_KEY
  temperature: 0.0
  max_tokens: 800

dataset:
  name: GSM8K
  split: test
  n_samples: 200  # Full run uses 200
  cache_dir: .cache

inference:
  batch_size: 1
  perturbations:
    - type: sentence_shuffle
      seed_offset: 0
    - type: add_irrelevant
      text: " Note: the sky is blue."
